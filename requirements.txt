import os
import asyncio
from datetime import datetime, timezone

import openai
openai.api_key = os.getenv("OPENAI_API_KEY")

from graphiti_core import Graphiti
from graphiti_core.nodes import EpisodeType

class ChatMemoryAgent:
    def __init__(self, neo4j_uri=None, user="neo4j", password=None, group_id="default"):
        self.group_id = group_id
        self.g = Graphiti(neo4j_uri, user, password)

    async def init(self):
        await self.g.build_indices_and_constraints()

    async def process_message(self, query: str) -> str:
        # 1. 从 Graphiti 检索与 query 相关的 facts（以 edge 形式返回）
        results = await self.g.search(
            query=query,
            num_results=5,
            group_ids=[self.group_id],
            search_scope="edges"
        )

        # 2. 构建提炼的 context 文本，注入系统 prompt
        facts_text = "\n".join(f"- {r.fact}" for r in results if r.fact)
        system_prompt = f"You are an assistant that remembers user history.\n\nRelevant facts:\n{facts_text or '＊无已知历史＊'}"

        # 3. 调用 LLM 生成回答
        resp = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": query}
            ],
            temperature=0.0
        )
        answer = resp.choices[0].message.content.strip()

        # 4. 把此次对话 turn 添加为新的 memory episode
        ep = f"User: {query}\nAssistant: {answer}"
        await self.g.add_episode(
            name=f"turn_{datetime.now(timezone.utc).timestamp()}",
            episode_body=ep,
            source=EpisodeType.message,
            source_description="chat turn",
            reference_time=datetime.now(timezone.utc),
            group_id=self.group_id
        )

        return answer

    async def close(self):
        await self.g.close()

async def main():
    ambot = ChatMemoryAgent(
        neo4j_uri=os.getenv("NEO4J_URI"),
        user=os.getenv("NEO4J_USER"),
        password=os.getenv("NEO4J_PASSWORD"),
        group_id="user_1234"
    )
    await ambot.init()

    questions = [
        "我叫 Alice，我最喜欢机器学习。",
        "请问我的名字是什么？",
        "我喜欢什么领域？"
    ]

    for q in questions:
        a = await ambot.process_message(q)
        print("→ Bot:", a, "\n")

    await ambot.close()

if __name__ == "__main__":
    asyncio.run(main())




＝＝＝＝＝＝＝＝＝＝＝＝＝＝



# knowledge_base_faqs.py
sample_faqs = [
  {
    "id": "faq_001",
    "question": "Graphiti 是什么？",
    "answer": "Graphiti 是 Zep 提供的开源时序知识图谱引擎，用于 agent 長期記憶管理。",
    "updated_at": "2025-07-31"
  },
  {
    "id": "faq_002",
    "question": "它支持哪些搜索方式？",
    "answer": "支持混合检索：向量语义（cosine）、BM25、图遍历 BFS。",
    "updated_at": "2024-12-18"
  },
  {
    "id": "faq_003",
    "question": "如何定义自定义实体类型？",
    "answer": "通过 Pydantic model 定义 entity schema，即可让 Graphiti 自动对齐实体。",
    "updated_at": "2025-03-24"
  }
]

import asyncio
from datetime import datetime, timezone
from graphiti_core import Graphiti
from graphiti_core.nodes import EpisodeType
from knowledge_base_faqs import sample_faqs

async def ingest_kb(kb, client: Graphiti, group_id="kb"):
    await client.build_indices_and_constraints()
    for faq in kb:
        await client.add_episode(
            name=faq["id"],
            episode_body=faq,
            source=EpisodeType.json,
            source_description="FAQ knowledge source",
            reference_time=datetime.fromisoformat(faq["updated_at"]).replace(tzinfo=timezone.utc),
            group_id=group_id
        )
    print(f"[✅] Ingested {len(kb)} KB FAQs into group '{group_id}'")

if __name__=="__main__":
    # 用你的 NEO4J 连接详情
    client = Graphiti(os.getenv("NEO4J_URI"), os.getenv("NEO4J_USER"), os.getenv("NEO4J_PASSWORD"))
    asyncio.run(ingest_kb(sample_faqs, client))


＃查询：
import os, json
import asyncio
from graphiti_core import Graphiti
from graphiti_core.nodes import EpisodeType
from datetime import datetime, timezone
import openai

openai.api_key = os.getenv("OPENAI_API_KEY")

class KBChatAgent:
    def __init__(self, neo4j_uri, user, password, kb_group="kb"):
        self.g = Graphiti(neo4j_uri, user, password)
        self.kb_group = kb_group

    async def init(self):
        await self.g.build_indices_and_constraints()

    async def answer_query(self, question: str) -> str:
        # 1. 从知识库中检索 top‑5 相关 fact（默认 EDGE 混合检索: 向量 + BM25 + BFS）
        res = await self.g.search(
            query=question,
            num_results=5,
            group_ids=[self.kb_group],
            search_scope="edges"
        )
        facts = [r.fact for r in res if r.fact]
        facts_md = "\n".join(f"- {f}" for f in facts) or "＊未检索到相关知识＊"

        # 2. 构造系统 prompt
        prompt = (
            "你是一个问答助手，查询以下 FAQ 知识：\n\n"
            f"{facts_md}\n\n用户问题：{question}\n\n"
            "若上方知识能回答用户问题，则直接回答。若没有覆盖，回答“对不起，我不知道”。"
        )

        resp = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": question}
            ],
            temperature=0.0
        )
        answer = resp.choices[0].message.content.strip()

        # 3. 可选：将问答对存入 Graphiti 做“对话记忆”
        await self.g.add_episode(
            name=f"qa_{datetime.now(timezone.utc).timestamp()}",
            episode_body=json.dumps({"user": question, "assistant": answer}),
            source=EpisodeType.message,
            source_description="user‑kb chat turn",
            reference_time=datetime.now(timezone.utc),
            group_id="dialog"
        )
        return answer

    async def close(self):
        await self.g.close()


async def run_demo():
    agent = KBChatAgent(os.getenv("NEO4J_URI"), os.getenv("NEO4J_USER"), os.getenv("NEO4J_PASSWORD"))
    await agent.init()
    for qry in ["Graphiti 支持哪些搜索方法？", "如何定义实体类型？", "Graphiti 是否可以做图片识别？"]:
        ans = await agent.answer_query(qry)
        print(qry, "→", ans, "\n")
    await agent.close()

if __name__=="__main__":
    asyncio.run(run_demo())
